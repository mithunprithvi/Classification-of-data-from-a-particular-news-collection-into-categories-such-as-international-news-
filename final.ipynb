{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ff0e92",
   "metadata": {},
   "source": [
    "# Classification of data from a particular news collection into categories such as international news and travel using machine learning and deep learning. Short description of the news dataset is used for the machine learning with category as a target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a6f694",
   "metadata": {},
   "source": [
    "Importing the required Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b375a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pandasForSortingCSV\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from nltk import *\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import pickle\n",
    "from pandas import DataFrame as df\n",
    "from datetime import datetime\n",
    "from IPython.display import display_html \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import make_scorer, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import keras.layers as layers\n",
    "from collections import Counter\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Input, Embedding, BatchNormalization, LSTM, Dense, Concatenate , Dropout\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import copy\n",
    "import numpy as np                                                               \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras import optimizers\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bf24ea",
   "metadata": {},
   "source": [
    " ##  Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579fff57",
   "metadata": {},
   "source": [
    "### 2.Loading  my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d162555",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata=pd.read_csv('21204205.csv', encoding='Latin1',dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883cb06c",
   "metadata": {},
   "source": [
    "Editing my dataset with preffered column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ed93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = mydata.set_axis([\"id\",\"category\",\"headline\",\"authors\",\"link\",\"short_description\",\"date\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d06a86",
   "metadata": {},
   "source": [
    "Viewing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4ff1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6b6472",
   "metadata": {},
   "source": [
    "## 3. iii) Removing the nan values and duplicates from the dataset since its a common occurence for the data to have duplicate values and empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1351d83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata=mydata.dropna()\n",
    "mydata=mydata.drop_duplicates()\n",
    "mydata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74ae900",
   "metadata": {},
   "source": [
    "Checking whether there is any empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d660eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c31468d",
   "metadata": {},
   "source": [
    "## Merging short description and headline into short description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a3f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata[\"short_description\"]=mydata['headline']+mydata['short_description']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b219b1b",
   "metadata": {},
   "source": [
    "### Preprocessing :Converting the whole dataset into lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5a0cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata['short_description'] = mydata['short_description'].str.lower()\n",
    "mydata['category'] = mydata['category'].str.lower()\n",
    "mydata['headline'] =[word.lower() for word in mydata['headline']]\n",
    "mydata['authors'] = [word.lower() for word in mydata['authors']]\n",
    "mydata['link'] = [word.lower() for word in mydata['link']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c88285",
   "metadata": {},
   "source": [
    "# Plotting the news data set as per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ac228",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata['category'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4630502c",
   "metadata": {},
   "source": [
    "##  After plotting the dataset in relation to category we noticed there is a imbalance and not equally distributed which may lead to predicting the best accuracy scores in travel category and fail to predict exact accuracy in world news category "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a696a3dd",
   "metadata": {},
   "source": [
    "Separating the dataset as per the category \"travel\" and \"world news\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e700203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata_travel=mydata[mydata[\"category\"] == 'travel']\n",
    "mydata_news=mydata[mydata[\"category\"] == 'world news']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747f5e38",
   "metadata": {},
   "source": [
    "## Considering the short description of the news dataset,Converting the string to a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edeafdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mydata_travel[\"short_description\"].values.tolist()\n",
    "# mydata_news[\"short_description\"].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8f600f",
   "metadata": {},
   "source": [
    "Defining Method to convert list to String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea22ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to convert list to String\n",
    "def listToString(s):\n",
    "    str1=\" \"\n",
    "    return(str1.join(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3ff48c",
   "metadata": {},
   "source": [
    "### Preprocessing the data using nltk methods (Tokenization,punctuation and stop words removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f667e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata_travel_token = nltk.word_tokenize(str(mydata_travel['short_description'].values.tolist()))\n",
    "mydata_news_token= nltk.word_tokenize(str(mydata_news['short_description'].values.tolist()))\n",
    "mydata_travel_no_punct = [t for t in mydata_travel_token if t.isalnum()]\n",
    "mydata_news_no_punct=[t for t in mydata_news_token if t.isalnum()]\n",
    "mydata_travel_no_stopwords = [t for t in mydata_travel_no_punct if t not in stopwords.words('english')] \n",
    "mydata_news_no_stopwords= [t for t in mydata_news_no_punct if t not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfd1e11",
   "metadata": {},
   "source": [
    "## 3.i)  Using Frequency distrubution finding the most common words in travel category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1154b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_travel = nltk.FreqDist(mydata_travel_no_stopwords)\n",
    "print(fd_travel.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e295e65",
   "metadata": {},
   "source": [
    "## 3.i)  Using Frequency distrubution finding the most common words in news category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a49a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_news = nltk.FreqDist(mydata_news_no_stopwords)\n",
    "print(fd_news.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c7a758",
   "metadata": {},
   "source": [
    "### 3.ii) Taking a copy of data to run feature selection using Chi-Square Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94258ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code reference: github.com\n",
    "\n",
    "DATAAA = pd.DataFrame(mydata)\n",
    "#Make a copy:\n",
    "featureselection = DATAAA.copy()\n",
    "print(featureselection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f33a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del featureselection[\"date\"]\n",
    "del featureselection[\"headline\"]\n",
    "del featureselection[\"authors\"]\n",
    "del featureselection[\"link\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c230e37",
   "metadata": {},
   "source": [
    "##  Visualization of category using chi-square test by feature selection. Since chi-square test  is measured on a nominal (categorical) scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b450667",
   "metadata": {},
   "outputs": [],
   "source": [
    "contigency= pd.crosstab(featureselection['short_description'], featureselection['category'])\n",
    "contigency_pct = pd.crosstab(featureselection['short_description'], featureselection['category'], normalize='index')\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(contigency, annot=True, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d42aab",
   "metadata": {},
   "source": [
    "### 3.iii) Length of sentences\n",
    "Defining a function to find length of each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4b4d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_length(text):\n",
    "    sentences = text.split(\",\")\n",
    "    words = text.split(\" \")\n",
    "    if(sentences[len(sentences)-1]==\"\"):\n",
    "       sentence_length = len(words)/len(sentences)-1\n",
    "    else:\n",
    "       sentence_length = len(words)/len(sentences)\n",
    "    return sentence_length\n",
    "#https://python-forum.io/thread-11585.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca14b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_avg=sentence_length(str(mydata_travel['short_description'].values.tolist()))\n",
    "news_avg=sentence_length(str(mydata_news['short_description'].values.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cce186c",
   "metadata": {},
   "source": [
    "Average of sentences in category \"travel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb33fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(travel_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b31ece",
   "metadata": {},
   "source": [
    "Average of sentences in category \"world news\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade3b01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(news_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdc1bf3",
   "metadata": {},
   "source": [
    "Viewing the columns of our data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e85fe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ec18e4",
   "metadata": {},
   "source": [
    "### Loaded the dataset and preprocessed by converting into lowercase,removing stop words,special characters to reduce the noice in the dataset, in addition to that we have removed duplicates and empty values. Found the most frequently used words in the short description of both world news and travel category . Used Chi-square test to display feature selection in relation with categories in the task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beb6704",
   "metadata": {},
   "source": [
    "\n",
    "#  Task 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb23f37",
   "metadata": {},
   "source": [
    "# Encoding the Category \"World news as 0\" and \"Travel as 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dfe869",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_category = mydata.category.unique()\n",
    "\n",
    "label_dict = {}\n",
    "for index, possible_categor in enumerate(possible_category):\n",
    "    label_dict[possible_categor] = index\n",
    "label_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c59d9a0",
   "metadata": {},
   "source": [
    "## Vectorizing the category id and category to be used as target while running classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cbe597",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata['c_id'] = mydata.category.replace(label_dict)\n",
    "mydata['category'] = mydata.category.replace(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f10abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c02eb2",
   "metadata": {},
   "source": [
    "### Splitting the dataset into X and y where X contains headline,authors,link,short description,date and category id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e11c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mydata.iloc[:,2:8]\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b711cdc1",
   "metadata": {},
   "source": [
    "### Setting y as a target(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8bebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = mydata['category']\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735bff77",
   "metadata": {},
   "source": [
    "## 4.i) Specifying the size of the dataset and spliting the dataset into combined train plus valid datasets with size 0.75 and a test dataset with size 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907257ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_plus_valid, X_test, y_train_plus_valid, y_test = train_test_split(X, y, random_state=0, test_size = 0.25, train_size = 0.75)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d94956d",
   "metadata": {},
   "source": [
    "### 4.i)Then again splitting the combined train plus valid dataset into separate train with size 0.5 and valid datasets as 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a8eac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_plus_valid, y_train_plus_valid, random_state=0, test_size = 0.25/0.75, train_size = 0.5/0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8032e988",
   "metadata": {},
   "source": [
    "### 4.ii) Storing the dataset into Excel csv files for train,test and valid datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cccbbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('train.csv',index=False)\n",
    "X_test.to_csv('test.csv',index=False)\n",
    "X_valid.to_csv('valid.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34932137",
   "metadata": {},
   "source": [
    "### 5.) Loading the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984d6d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eda90c",
   "metadata": {},
   "source": [
    "Removing every columns other than short description to run classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87119dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['authors']\n",
    "del train['link']\n",
    "del train['headline']\n",
    "del train['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f0a6d0",
   "metadata": {},
   "source": [
    "Loading the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68cae8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de86e256",
   "metadata": {},
   "source": [
    "### Preprocessing the train dataset like removing tags, special character and stop words to remove noise in the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d988f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(text):\n",
    "  remove = re.compile(r'')\n",
    "  return re.sub(remove, '', text)\n",
    "train['short_description'] = train['short_description'].apply(remove_tags)\n",
    "\n",
    "def special_char(text):\n",
    "  reviews = ''\n",
    "  for x in text:\n",
    "    if x.isalnum():\n",
    "      reviews = reviews + x\n",
    "    else:\n",
    "      reviews = reviews + ' '\n",
    "  return reviews\n",
    "train['short_description'] = train['short_description'].apply(special_char)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  words = word_tokenize(text)\n",
    "  return \" \".join([x for x in words if x not in stop_words])\n",
    "train['short_description'] = train['short_description'].apply(remove_stopwords)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d9bcaa",
   "metadata": {},
   "source": [
    "Vectorizing the Short description of train dataset using term frequency vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b0fdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vecttrain = TfidfVectorizer(analyzer='word', max_features=6000)\n",
    "\n",
    "x_tfidftrain = tfidf_vecttrain.fit_transform(train['short_description'])\n",
    "\n",
    "x_featurestrain = pd.DataFrame(x_tfidftrain.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d0019c",
   "metadata": {},
   "source": [
    "Splitiing the train dataset into train and test to run classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caa0ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_traint, y_testt = train_test_split(x_featurestrain, train['c_id'], test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6840f186",
   "metadata": {},
   "source": [
    "## 6. Decision Tree classifier,Random forest classifier,Logistic Regression,Multinomial NB, K-Nearest neighbour and Linear SVC classifiers were used on train dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af3c72d",
   "metadata": {},
   "source": [
    "Saving the model using decision tree classifier on train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2d6d12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dtctrain = DecisionTreeClassifier(max_depth=500)\n",
    "\n",
    "#dt_modeltrain = dtctrain.fit(x_train, y_traint)\n",
    "\n",
    "# preddtctrain = dt_modeltrain.predict(x_test)\n",
    "\n",
    "# print('Accuracy score :- {}'.format(round(accuracy_score(y_testt, preddtctrain), 2)))\n",
    "\n",
    "# print(format(classification_report(y_testt, preddtctrain,zero_division=1)))\n",
    "\n",
    "dt_modeltrain = DecisionTreeClassifier().fit(x_train, y_traint)\n",
    "mymodel = open('dtctrain1.sav', 'wb')\n",
    "pickle.dump( dt_modeltrain, mymodel)\n",
    "mymodel.close()\n",
    "preddtctrain = dt_modeltrain.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86222667",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'dtctrain1.sav'\n",
    "saved_clf = pickle.load(open(filename, 'rb'))\n",
    "saved_clf.score(x_test, y_testt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb12ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---Test Set Results---\")\n",
    "print(\"Accuracy with logreg: {}\".format(accuracy_score(y_testt, preddtctrain)))\n",
    "print(classification_report(y_testt, preddtctrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7156703",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324c7844",
   "metadata": {},
   "source": [
    "### 8. Confusion matrix is a primary metric used to evaluate my models for summarizing the performance of a classification algorithm. The number of correct and incorrect predictions are summarized with count values and broken down by each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6c874c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_testt, preddtctrain) #you will need to change the latter to your desired output\n",
    "cm\n",
    " \n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #Don't worry too much about the arguments here - we will return to this! \n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix');\n",
    "ax.xaxis.set_ticklabels(['<=50K', '>50K']); ax.yaxis.set_ticklabels(['<=50K','>50K' ]);\n",
    "TN, FP, FN, TP = confusion_matrix(y_testt, preddtctrain).ravel()\n",
    "\n",
    "print('True Positive(TP)  = ', TP)\n",
    "print('False Positive(FP) = ', FP)\n",
    "print('True Negative(TN)  = ', TN)\n",
    "print('False Negative(FN) = ', FN)\n",
    "print('Accuracy score :- {}'.format(round(accuracy_score(y_testt, preddtctrain), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc31233e",
   "metadata": {},
   "source": [
    "Storing Predicted values into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6912c238",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcpreda = pd.DataFrame(preddtctrain)\n",
    "dtcpreda.columns = [\"DTC\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54180b02",
   "metadata": {},
   "source": [
    "Running random forest classifier on train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4a4850",
   "metadata": {},
   "source": [
    "# 9.  The most accurate classifiers are decision tree classifier which has 0.91 and random forest classifier has the most accuracy score of 0.87 when compared to linear regression, multinomial nb and linear svc on train dataset and saving those models using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfctrain = RandomForestClassifier()\n",
    "\n",
    "# rfc_modeltrain = rfctrain.fit(x_train, y_traint)\n",
    "\n",
    "# rfcpredtrain = rfc_modeltrain.predict(x_test)\n",
    "\n",
    "# print('Accuracy score :- {}'.format(round(accuracy_score(y_testt, rfcpredtrain), 2)))\n",
    "\n",
    "# print(format(classification_report(y_testt, rfcpredtrain,zero_division=1)))\n",
    "rfc_modeltrain = RandomForestClassifier().fit(x_train, y_traint)\n",
    "mymodel = open('rtctrain1.sav', 'wb')\n",
    "pickle.dump( rfc_modeltrain, mymodel)\n",
    "mymodel.close()\n",
    "rfcpredtrain = rfc_modeltrain.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaf346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'rtctrain1.sav'\n",
    "saved_clf = pickle.load(open(filename, 'rb'))\n",
    "saved_clf.score(x_test, y_testt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f13f494",
   "metadata": {},
   "source": [
    "### 10) Running classification report and confusion matrix for error analysis providing true positive,false positive,true negative,false negative and f-1 scores, precision, recall and support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a520578",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---Test Set Results---\")\n",
    "print(\"Accuracy with logreg: {}\".format(accuracy_score(y_testt, rfcpredtrain)))\n",
    "print(classification_report(y_testt, rfcpredtrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81eb589",
   "metadata": {},
   "source": [
    "Running Confusion matrix for error analysis on train dataset for random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e957112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_testt, rfcpredtrain) #you will need to change the latter to your desired output\n",
    "cm\n",
    " \n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #Don't worry too much about the arguments here - we will return to this! \n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix');\n",
    "ax.xaxis.set_ticklabels(['<=50K', '>50K']); ax.yaxis.set_ticklabels(['<=50K','>50K' ]);\n",
    "TN, FP, FN, TP = confusion_matrix(y_testt, rfcpredtrain).ravel()\n",
    "\n",
    "print('True Positive(TP)  = ', TP)\n",
    "print('False Positive(FP) = ', FP)\n",
    "print('True Negative(TN)  = ', TN)\n",
    "print('False Negative(FN) = ', FN)\n",
    "print('Accuracy score :- {}'.format(round(accuracy_score(y_testt, rfcpredtrain), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9c8a90",
   "metadata": {},
   "source": [
    "Storing Predicted values into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda72b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcpredaa = pd.DataFrame(rfcpredtrain)\n",
    "rfcpredaa.columns = [\"RFC\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ab0591",
   "metadata": {},
   "source": [
    "Predicted values after using classifiers on train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d220187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://softhints.com/display-two-pandas-dataframes-side-by-side-jupyter-notebook/\n",
    "df3_styler = dtcpreda.style.set_table_attributes(\"style='display:inline'\")\n",
    "df4_styler = rfcpredaa.style.set_table_attributes(\"style='display:inline'\")\n",
    "display_html(df4_styler._repr_html_()+df3_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d771183",
   "metadata": {},
   "source": [
    "Loading the valid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d58e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid=pd.read_csv('valid.csv')\n",
    "valid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e30f3c",
   "metadata": {},
   "source": [
    "Removing every columns other than short description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a69504",
   "metadata": {},
   "outputs": [],
   "source": [
    "del valid['authors']\n",
    "del valid['link']\n",
    "del valid['headline']\n",
    "del valid['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8de3c3d",
   "metadata": {},
   "source": [
    "Preprocessing the valid dataset like removing tags, special character and stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5da2802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(text):\n",
    "  remove = re.compile(r'')\n",
    "  return re.sub(remove, '', text)\n",
    "valid['short_description'] = valid['short_description'].apply(remove_tags)\n",
    "\n",
    "def special_char(text):\n",
    "  reviews = ''\n",
    "  for x in text:\n",
    "    if x.isalnum():\n",
    "      reviews = reviews + x\n",
    "    else:\n",
    "      reviews = reviews + ' '\n",
    "  return reviews\n",
    "valid['short_description'] = valid['short_description'].apply(special_char)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  words = word_tokenize(text)\n",
    "  return \" \".join([x for x in words if x not in stop_words])\n",
    "valid['short_description'] = valid['short_description'].apply(remove_stopwords)\n",
    "\n",
    "valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b88bf2",
   "metadata": {},
   "source": [
    "Vectorizing the Short description of valid dataset \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e04e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectvalid = TfidfVectorizer(analyzer='word', max_features=6000)\n",
    "\n",
    "x_tfidfvalid = tfidf_vectvalid.fit_transform(valid['short_description'])\n",
    "\n",
    "x_featuresvalid = pd.DataFrame(x_tfidfvalid.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab3dd52",
   "metadata": {},
   "source": [
    "Splitiing the valid dataset into train and test to run classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2707e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x_featuresvalid, valid['c_id'], test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98009e4d",
   "metadata": {},
   "source": [
    "Decision Tree classifier,Random forest classifier,Logistic Regression,Multinomial NB, K-Nearest neighbour and Linear SVC classifiers were used on valid dataset and the most accurate ones are saved below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50931d3b",
   "metadata": {},
   "source": [
    "Running decision tree classifier on valid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc6c3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtcvalid = DecisionTreeClassifier(max_depth=500)\n",
    "\n",
    "# dtcvalid_model = dtcvalid.fit(x_train1, y_train1)\n",
    "\n",
    "# validdtcpred = dtcvalid_model.predict(x_test1)\n",
    "\n",
    "# print('Accuracy score :- {}'.format(round(accuracy_score(y_test1, validdtcpred), 2)))\n",
    "\n",
    "# print(format(classification_report(y_test1, validdtcpred,zero_division=1)))\n",
    "\n",
    "dtcvalid_model = DecisionTreeClassifier().fit(x_train1, y_train1)\n",
    "mymodel = open('dtctrain1.sav', 'wb')\n",
    "pickle.dump( dtcvalid_model, mymodel)\n",
    "mymodel.close()\n",
    "validdtcpred = dtcvalid_model.predict(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74672666",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'dtctrain1.sav'\n",
    "saved_clf = pickle.load(open(filename, 'rb'))\n",
    "saved_clf.score(x_test1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012195b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---Test Set Results---\")\n",
    "print(\"Accuracy with logreg: {}\".format(accuracy_score(y_test1, validdtcpred)))\n",
    "print(classification_report(y_test1, validdtcpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f696cfc7",
   "metadata": {},
   "source": [
    "Running Confusion matrix for error analysis on valid dataset for decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a28fd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test1, validdtcpred) #you will need to change the latter to your desired output\n",
    "cm\n",
    " \n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #Don't worry too much about the arguments here - we will return to this! \n",
    "\n",
    " #labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix');\n",
    "ax.xaxis.set_ticklabels(['<=50K', '>50K']); ax.yaxis.set_ticklabels(['<=50K','>50K' ]);\n",
    "TN, FP, FN, TP = confusion_matrix(y_test1, validdtcpred).ravel()\n",
    "\n",
    "print('True Positive(TP)  = ', TP)\n",
    "print('False Positive(FP) = ', FP)\n",
    "print('True Negative(TN)  = ', TN)\n",
    "print('False Negative(FN) = ', FN)\n",
    "\n",
    "print('Accuracy score :- {}'.format(round(accuracy_score(y_test1, validdtcpred), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805361e9",
   "metadata": {},
   "source": [
    "Storing Predicted values into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cfce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcvalidpred = pd.DataFrame(validdtcpred)\n",
    "dtcvalidpred.columns = [\"Decision Tree Classifier\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d381bd3d",
   "metadata": {},
   "source": [
    "### 9. Accuracy scores of the valid datasets were 0.82 for the decision tree classifer and 0.8 using the random forest classifier are used while other classifiers had less accuracy scores. Accuracy scores of valid is less than the train dataset since the valid dataset has very less data when compared to train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6358b0c",
   "metadata": {},
   "source": [
    "Running random forest classifier on valid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ce9e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfcvalid = RandomForestClassifier()\n",
    "\n",
    "# rfcv_model = rfcvalid.fit(x_train1, y_train1)\n",
    "\n",
    "# rfcpredvalid = rfcv_model.predict(x_test1)\n",
    "\n",
    "# print('Accuracy score :- {}'.format(round(accuracy_score(y_test1, rfcpredvalid), 2)))\n",
    "\n",
    "# print(format(classification_report(y_test1, rfcpredvalid,zero_division=1)))\n",
    "rfcv_model = RandomForestClassifier().fit(x_train1, y_train1)\n",
    "mymodel = open('rtctrain1.sav', 'wb')\n",
    "pickle.dump( rfcv_model, mymodel)\n",
    "mymodel.close()\n",
    "rfcpredvalid = rfcv_model.predict(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19355bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'rtctrain1.sav'\n",
    "saved_clf = pickle.load(open(filename, 'rb'))\n",
    "saved_clf.score(x_test1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36130cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---Test Set Results---\")\n",
    "print(\"Accuracy with logreg: {}\".format(accuracy_score(y_test1, rfcpredvalid)))\n",
    "print(classification_report(y_test1, rfcpredvalid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de7ea73",
   "metadata": {},
   "source": [
    "Running Confusion matrix for error analysis on valid dataset for random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b25426",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test1, rfcpredvalid) #you will need to change the latter to your desired output\n",
    "cm\n",
    " \n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #Don't worry too much about the arguments here - we will return to this! \n",
    "\n",
    " #labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix');\n",
    "ax.xaxis.set_ticklabels(['<=50K', '>50K']); ax.yaxis.set_ticklabels(['<=50K','>50K' ]);\n",
    "TN, FP, FN, TP = confusion_matrix(y_test1, rfcpredvalid).ravel()\n",
    "\n",
    "print('True Positive(TP)  = ', TP)\n",
    "print('False Positive(FP) = ', FP)\n",
    "print('True Negative(TN)  = ', TN)\n",
    "print('False Negative(FN) = ', FN)\n",
    "\n",
    "print('Accuracy score :- {}'.format(round(accuracy_score(y_test1, rfcpredvalid), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fba720a",
   "metadata": {},
   "source": [
    "Storing Predicted values into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a46ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcpredaav = pd.DataFrame(rfcpredvalid)\n",
    "rfcpredaav.columns = [\"RFC\"]\n",
    "rfcpredaav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6364bde",
   "metadata": {},
   "source": [
    "Printing Predicted values after using classifiers on valid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30786ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://softhints.com/display-two-pandas-dataframes-side-by-side-jupyter-notebook/\n",
    "df3_styler = dtcvalidpred.style.set_table_attributes(\"style='display:inline'\").set_caption('df3')\n",
    "df4_styler = rfcpredaav.style.set_table_attributes(\"style='display:inline'\").set_caption('df4')\n",
    "display_html(df4_styler._repr_html_()+df3_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1641a1d1",
   "metadata": {},
   "source": [
    "# 11.)Adding a preprocessing technique to train dataset and using classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02072090",
   "metadata": {},
   "source": [
    "Making a copy of train data set into trainmod dataset to use classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cae271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "traina = pd.DataFrame(train)\n",
    "\n",
    "#Make a copy:\n",
    "\n",
    "trainmod = traina.copy()\n",
    "\n",
    "print(trainmod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a08a3",
   "metadata": {},
   "source": [
    "### Adding a preprocessing technique lemmatization to the train modification dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76114c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "#code reference: stackoverflow.com\n",
    "def lemmatize_text(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)])\n",
    "trainmod['short_description'] = trainmod.short_description.apply(lemmatize_text)\n",
    "print(trainmod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c4d259",
   "metadata": {},
   "source": [
    "Vectorizing the Short description of train modified dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae9c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectt_modifiedtrain = TfidfVectorizer(analyzer='word', max_features=6000)\n",
    "\n",
    "x_tfidfft_modifiedtrain = tfidf_vectt_modifiedtrain.fit_transform(trainmod['short_description'])\n",
    "\n",
    "x_featuress_modifiedtrain= pd.DataFrame(x_tfidfft_modifiedtrain .toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c50910",
   "metadata": {},
   "source": [
    "Splitiing the train modified dataset into train and test to run classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e82fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_m, x_test_m, y_train_m, y_test_m = train_test_split(x_featuress_modifiedtrain, trainmod['c_id'], test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783ec4cb",
   "metadata": {},
   "source": [
    "Decision Tree classifier,Random forest classifier,Logistic Regression,Multinomial NB, K-Nearest neighbour and Linear SVC classifiers were used on train modified dataset and the most accurate ones are saved below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d12671",
   "metadata": {},
   "source": [
    "Running decision tree classifier on train modified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c83bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtc = DecisionTreeClassifier(max_depth=500)\n",
    "\n",
    "# dt_model = dtc.fit(x_train_m, y_train_m)\n",
    "\n",
    "# preddtc_m = dt_model.predict(x_test_m)\n",
    "\n",
    "# print('Accuracy score :- {}'.format(round(accuracy_score(y_test_m, preddtc_m), 2)))\n",
    "\n",
    "# print(format(classification_report(y_test_m, preddtc_m,zero_division=1)))\n",
    "dt_model = DecisionTreeClassifier().fit(x_train_m, y_train_m)\n",
    "mymodel = open('dtctrainmod.sav', 'wb')\n",
    "pickle.dump( dt_model, mymodel)\n",
    "mymodel.close()\n",
    "preddtc_m = dt_model.predict(x_test_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c187618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'dtctrainmod.sav'\n",
    "saved_clf = pickle.load(open(filename, 'rb'))\n",
    "saved_clf.score(x_test_m, y_test_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db263728",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---Test Set Results---\")\n",
    "print(\"Accuracy with logreg: {}\".format(accuracy_score(y_test_m, preddtc_m)))\n",
    "print(classification_report(y_test_m, preddtc_m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f773e",
   "metadata": {},
   "source": [
    "Storing Predicted values of train modified into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed35a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcpreda = pd.DataFrame(preddtc_m)\n",
    "dtcpreda.columns = [\"DTC\"]\n",
    "dtcpreda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac32ce7f",
   "metadata": {},
   "source": [
    "Running Confusion matrix for error analysis on train modified dataset for decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c120d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test_m, preddtc_m) #you will need to change the latter to your desired output\n",
    "cm\n",
    " \n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #Don't worry too much about the arguments here - we will return to this! \n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix');\n",
    "#ax.xaxis.set_ticklabels(['<=50K', '>50K']); ax.yaxis.set_ticklabels(['<=50K','>50K' ]);\n",
    "TN, FP, FN, TP = confusion_matrix(y_test_m, preddtc_m).ravel()\n",
    "\n",
    "print('True Positive(TP)  = ', TP)\n",
    "print('False Positive(FP) = ', FP)\n",
    "print('True Negative(TN)  = ', TN)\n",
    "print('False Negative(FN) = ', FN)\n",
    "\n",
    "print('Accuracy score :- {}'.format(round(accuracy_score(y_test_m, preddtc_m), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda8c9dc",
   "metadata": {},
   "source": [
    "Running random forest classifier on train modified dataset and saved to a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0dd3e7",
   "metadata": {},
   "source": [
    "# 11) After lemmatization, a modification in the train set has the performance accuracy score in random forest classifier better then the train dataset and saving the model below using pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e0781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfctrainmod = RandomForestClassifier().fit(x_train_m, y_train_m)\n",
    "mymodel = open('rtctrainmod.sav', 'wb')\n",
    "pickle.dump(rfctrainmod, mymodel)\n",
    "mymodel.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835494d2",
   "metadata": {},
   "source": [
    "Loading the model using pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106d17b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'rtctrainmod.sav'\n",
    "saved_clf = pickle.load(open(filename, 'rb'))\n",
    "saved_clf.score(x_test_m, y_test_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9611112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preCIONNNN = rfctrainmod.predict(x_test_m)\n",
    "print(\"---Test Set Results---\")\n",
    "print(\"Accuracy with logreg: {}\".format(accuracy_score(y_test_m, y_preCIONNNN)))\n",
    "print(classification_report(y_test_m, y_preCIONNNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a65f4ec",
   "metadata": {},
   "source": [
    "Running Confusion matrix for error analysis on train modified dataset for random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7611539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm=confusion_matrix(y_test_m, y_preCIONNNN) #you will need to change the latter to your desired output\n",
    "cm\n",
    " \n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #Don't worry too much about the arguments here - we will return to this! \n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix');\n",
    "#ax.xaxis.set_ticklabels(['<=50K', '>50K']); ax.yaxis.set_ticklabels(['<=50K','>50K' ]);\n",
    "TN, FP, FN, TP = confusion_matrix(y_test_m, y_preCIONNNN).ravel()\n",
    "\n",
    "print('True Positive(TP)  = ', TP)\n",
    "print('False Positive(FP) = ', FP)\n",
    "print('True Negative(TN)  = ', TN)\n",
    "print('False Negative(FN) = ', FN)\n",
    "\n",
    "print('Accuracy score :- {}'.format(round(accuracy_score(y_test_m, y_preCIONNNN), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70541d22",
   "metadata": {},
   "source": [
    "Storing Predicted values of train modified into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d56291",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcpredaa = pd.DataFrame(y_preCIONNNN)\n",
    "rfcpredaa.columns = [\"rfc\"]\n",
    "rfcpredaa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f4540d",
   "metadata": {},
   "source": [
    "Printing Predicted values after using classifiers on valid modified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cfef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_styler = dtcpreda.style.set_table_attributes(\"style='display:inline'\").set_caption('df3')\n",
    "df4_styler = rfcpredaa.style.set_table_attributes(\"style='display:inline'\").set_caption('df4')\n",
    "\n",
    "\n",
    "display_html(df4_styler._repr_html_()+df3_styler._repr_html_(), raw=True)\n",
    "\n",
    "\n",
    "#https://softhints.com/display-two-pandas-dataframes-side-by-side-jupyter-notebook/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3017549e",
   "metadata": {},
   "source": [
    "Making a copy of valid dataframe to modify and apply classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ca7ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "valida = pd.DataFrame(valid)\n",
    "\n",
    "#Make a copy:\n",
    "\n",
    "validmod = valida.copy()\n",
    "\n",
    "print(validmod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396416a6",
   "metadata": {},
   "source": [
    "#### Adding a preprocessing technique lemmatization to the valid modification dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71a73b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)])\n",
    "\n",
    "\n",
    "validmod['short_description'] = validmod.short_description.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dd0bf3",
   "metadata": {},
   "source": [
    "The valid modified dataset is now vectorized using term frequency vectorizer and then split into train and test for running classifers such as KNN,Decision Tree,Random Forest,Multinomial NB and Linear SVC. The Models with greater accuracy scores are saved and predicted values are printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddda328",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectv_validmod = TfidfVectorizer(analyzer='word', max_features=6000)\n",
    "\n",
    "x_tfidfvalidm = tfidf_vectv_validmod.fit_transform(validmod['short_description'])\n",
    "\n",
    "x_features_validm = pd.DataFrame(x_tfidfvalidm.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a74d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validm, x_test_vm, y_validm, y_test_vm = train_test_split(x_features_validm, validmod['c_id'], test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dabd441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtcv = DecisionTreeClassifier(max_depth=500)\n",
    "\n",
    "# dt_modelv = dtcv.fit(x_validm, y_validm)\n",
    "\n",
    "# preddtcv = dt_modelv.predict(x_test_vm)\n",
    "\n",
    "# print('Accuracy score :- {}'.format(round(accuracy_score(y_test_vm, preddtcv), 2)))\n",
    "\n",
    "# print(format(classification_report(y_test_vm, preddtcv,zero_division=1)))\n",
    "dt_modelv = DecisionTreeClassifier().fit(x_validm, y_validm)\n",
    "mymodel = open('dtctrainmod.sav', 'wb')\n",
    "pickle.dump( dt_modelv, mymodel)\n",
    "mymodel.close()\n",
    "preddtcv = dt_modelv.predict(x_test_vm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a254ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'dtctrainmod.sav'\n",
    "saved_clf = pickle.load(open(filename, 'rb'))\n",
    "saved_clf.score(x_test_vm, y_test_vm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9937b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"---Test Set Results---\")\n",
    "print(\"Accuracy with logreg: {}\".format(accuracy_score(y_test_vm, preddtcv)))\n",
    "print(classification_report(y_test_vm, preddtcv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c58270",
   "metadata": {},
   "source": [
    "## After lemmatization on valid dataset, the decision tree classifier of valid dataset the accuracy scores improved to 0.81 from 0.83 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafcaf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test_vm, preddtcv) #you will need to change the latter to your desired output\n",
    "cm\n",
    " \n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #Don't worry too much about the arguments here - we will return to this! \n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix');\n",
    "#ax.xaxis.set_ticklabels(['<=50K', '>50K']); ax.yaxis.set_ticklabels(['<=50K','>50K' ]);\n",
    "TN, FP, FN, TP = confusion_matrix(y_test_vm, preddtcv).ravel()\n",
    "\n",
    "print('True Positive(TP)  = ', TP)\n",
    "print('False Positive(FP) = ', FP)\n",
    "print('True Negative(TN)  = ', TN)\n",
    "print('False Negative(FN) = ', FN)\n",
    "\n",
    "print('Accuracy score :- {}'.format(round(accuracy_score(y_test_vm, preddtcv), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916ff2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcpreda = pd.DataFrame(preddtcv)\n",
    "dtcpreda.columns = [\"DTC\"]\n",
    "dtcpreda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f9794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfcv = RandomForestClassifier()\n",
    "\n",
    "# rfc_modelv = rfcv.fit(x_validm, y_validm)\n",
    "\n",
    "# rfcpredav = rfc_modelv.predict(x_test_vm)\n",
    "\n",
    "# print('Accuracy score :- {}'.format(round(accuracy_score(y_test_vm, rfcpredav), 2)))\n",
    "\n",
    "# print(format(classification_report(y_test_vm, rfcpredav,zero_division=1)))#\n",
    "rfc_modelv = RandomForestClassifier().fit(x_validm, y_validm)\n",
    "mymodel = open('rtctrainmod.sav', 'wb')\n",
    "pickle.dump( rfc_modelv, mymodel)\n",
    "mymodel.close()\n",
    "rfcpredav = rfc_modelv.predict(x_test_vm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f264019",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'rtctrainmod.sav'\n",
    "saved_clf = pickle.load(open(filename, 'rb'))\n",
    "saved_clf.score(x_test_vm, y_test_vm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7462a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---Test Set Results---\")\n",
    "print(\"Accuracy with logreg: {}\".format(accuracy_score(y_test_vm, rfcpredav)))\n",
    "print(classification_report(y_test_vm, rfcpredav))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f372cff",
   "metadata": {},
   "source": [
    "## After lemmatization on valid dataset, the random forest classifier of valid dataset the accuracy scored improved to 0.82 from 0.81 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced93d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test_vm, rfcpredav) #you will need to change the latter to your desired output\n",
    "cm\n",
    " \n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #Don't worry too much about the arguments here - we will return to this! \n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix');\n",
    "#ax.xaxis.set_ticklabels(['<=50K', '>50K']); ax.yaxis.set_ticklabels(['<=50K','>50K' ]);\n",
    "TN, FP, FN, TP = confusion_matrix(y_test_vm, rfcpredav).ravel()\n",
    "\n",
    "print('True Positive(TP)  = ', TP)\n",
    "print('False Positive(FP) = ', FP)\n",
    "print('True Negative(TN)  = ', TN)\n",
    "print('False Negative(FN) = ', FN)\n",
    "\n",
    "print('Accuracy score :- {}'.format(round(accuracy_score(y_test_vm, rfcpredav), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a497d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcpredaa = pd.DataFrame(rfcpredav)\n",
    "rfcpredaa.columns = [\"rfc\"]\n",
    "rfcpredaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80350e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_styler = dtcpreda.style.set_table_attributes(\"style='display:inline'\").set_caption('df3')\n",
    "df4_styler = rfcpredaa.style.set_table_attributes(\"style='display:inline'\").set_caption('df4')\n",
    "display_html(df4_styler._repr_html_()+df3_styler._repr_html_(), raw=True)\n",
    "\n",
    "#https://softhints.com/display-two-pandas-dataframes-side-by-side-jupyter-notebook/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712a4895",
   "metadata": {},
   "source": [
    "# 12)Merging the Train and valid dataset into one dataset and performing preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383de13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_X = pd.concat([X_train, X_valid], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a35455",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487fba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_Y = pd.concat([y_train, y_valid], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b3530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ac42af",
   "metadata": {},
   "source": [
    "Preprocessing the merged dataset by removing stopwords, lemmatizing and removing other columns rather than short description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51470162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  words = word_tokenize(text)\n",
    "  return \" \".join([x for x in words if x not in stop_words])\n",
    "a_X['short_description'] = a_X['short_description'].apply(remove_stopwords)\n",
    "a_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3faeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)])\n",
    "\n",
    "\n",
    "a_X['short_description'] = a_X.short_description.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6529d803",
   "metadata": {},
   "outputs": [],
   "source": [
    "del a_X['authors']\n",
    "del a_X['link']\n",
    "del a_X['headline']\n",
    "del a_X['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957383ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "del a_X['c_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de881789",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35136b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def special_char(text):\n",
    "  reviews = ''\n",
    "  for x in text:\n",
    "    if x.isalnum():\n",
    "      reviews = reviews + x\n",
    "    else:\n",
    "      reviews = reviews + ' '\n",
    "  return reviews\n",
    "a_X['short_description'] = a_X['short_description'].apply(special_char)\n",
    "a_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaab57b",
   "metadata": {},
   "source": [
    "Vectorizing the short description of merged train and valid dataset using term frequency vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e921f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectt_merged = TfidfVectorizer(analyzer='word', max_features=6000)\n",
    "\n",
    "x_tfidfft_merged = tfidf_vectt_merged.fit_transform(a_X['short_description'])\n",
    "\n",
    "x_featuress_tmerged= pd.DataFrame(x_tfidfft_merged .toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5833471c",
   "metadata": {},
   "source": [
    "Initialising our KFold object with 5 splits to run K-fold Cross Validation on merged train and valid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad65b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90d7e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_val_score(dt_modelv , x_featuress_tmerged, a_Y, cv = folder)# Parameters are, in order - model, X data, labels (y), and the KFold object\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f2b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = df(results, columns=[\"Accuracy_per_fold\"])\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1483423",
   "metadata": {},
   "source": [
    "Accuracy of K-Fold Cross Validation using Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315fbfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean of the column!\n",
    "av_val = output[\"Accuracy_per_fold\"].mean()*100\n",
    "print(\"The average accuracy across folds is {}%\".format(av_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189fc974",
   "metadata": {},
   "source": [
    "Initialising our KFold object with 5 splits to run K-fold Cross Validation on merged train and valid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b552d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = cross_val_score(rfc_modelv , x_featuress_tmerged, a_Y, cv = folder)# Parameters are, in order - model, X data, labels (y), and the KFold object\n",
    "results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed94ce48",
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = df(results1, columns=[\"Accuracy_per_fold\"])\n",
    "output1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ed34da",
   "metadata": {},
   "source": [
    "Accuracy of K-Fold Cross Validation using Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc75d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the mean of the column!\n",
    "av_val = output1[\"Accuracy_per_fold\"].mean()*100\n",
    "print(\"The average accuracy across folds is {}%\".format(av_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f782cede",
   "metadata": {},
   "source": [
    "### After doing cross validating using K-Fold using Decision Tree classifier and Random forest classiffier. Accuracy scores of Random Forest classifier were greater which is 87.6948 than decision tree classifier which is 82.24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4959e2",
   "metadata": {},
   "source": [
    "## 13. Choosing the random forest classifier to run on test dataset after doing modification in the train dataset which has the best accuracy scores from 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958ca2ee",
   "metadata": {},
   "source": [
    "Loading the test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c067fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "testtt=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892afa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "testtt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c5846e",
   "metadata": {},
   "source": [
    "Removing all the column rather than short description and category in Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa21244",
   "metadata": {},
   "outputs": [],
   "source": [
    "del testtt['authors']\n",
    "del testtt['link']\n",
    "del testtt['headline']\n",
    "del testtt['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ce060b",
   "metadata": {},
   "source": [
    "Preprocessing techniques like removing tags,special characters,stop words and lemmatizing the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4540feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(text):\n",
    "  remove = re.compile(r'')\n",
    "  return re.sub(remove, '', text)\n",
    "testtt['short_description'] = testtt['short_description'].apply(remove_tags)\n",
    "\n",
    "def special_char(text):\n",
    "  reviews = ''\n",
    "  for x in text:\n",
    "    if x.isalnum():\n",
    "      reviews = reviews + x\n",
    "    else:\n",
    "      reviews = reviews + ' '\n",
    "  return reviews\n",
    "testtt['short_description'] = testtt['short_description'].apply(special_char)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  words = word_tokenize(text)\n",
    "  return \" \".join([x for x in words if x not in stop_words])\n",
    "testtt['short_description'] = testtt['short_description'].apply(remove_stopwords)\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)])\n",
    "\n",
    "\n",
    "testtt['short_description'] = testtt.short_description.apply(lemmatize_text)\n",
    "testtt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f8cee",
   "metadata": {},
   "source": [
    "Vectorizing using Term frequency vectorizer on test dataset for short description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb54da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test= TfidfVectorizer(analyzer='word', max_features=6000)\n",
    "\n",
    "x_tfidftest= tfidf_test.fit_transform(testtt['short_description'])\n",
    "\n",
    "x_featuresxtest = pd.DataFrame(x_tfidftest.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcda0505",
   "metadata": {},
   "source": [
    "Splitiing the test dataset into train and test to use classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1915a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traintest, x_testtest, y_traintest, y_testtest = train_test_split(x_featuresxtest, testtt['c_id'], test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d190abe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcmerged_model = RandomForestClassifier().fit(x_traintest, y_traintest)\n",
    "mymodel = open('rtctrainmod.sav', 'wb')\n",
    "pickle.dump( rfcmerged_model, mymodel)\n",
    "mymodel.close()\n",
    "rfcpredav = rfcmerged_model.predict(x_testtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef3b8f8",
   "metadata": {},
   "source": [
    "### Loading the best accuracy random forest classifier model saved from train modified dataset into test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ff3922",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'rtctrainmod.sav'\n",
    "saved_clf = pickle.load(open(filename, 'rb'))\n",
    "saved_clf.score(x_testtest, y_testtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ca8144",
   "metadata": {},
   "source": [
    "The accuracy obtained in test model using the saved model from modified train dataset is 0.90 which has increased previously from valid modified "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b872b0a9",
   "metadata": {},
   "source": [
    "Accuracy classification report with error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a70479",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---Test Set Results---\")\n",
    "print(\"Accuracy with logreg: {}\".format(accuracy_score(y_testtest, rfcpredav)))\n",
    "print(classification_report(y_testtest, rfcpredav))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12ef155",
   "metadata": {},
   "source": [
    "Splitiing themerged dataset train and valid merged dataset to run classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72820ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mergedd, x_test_merged, y_train_merged, y_test_merged = train_test_split(x_featuress_tmerged, a_Y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a3136a",
   "metadata": {},
   "source": [
    "## Running random forest classifier on merged dataset as it gave the best accuracy score on cross validation of merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fac9f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfcmergedd = RandomForestClassifier()\n",
    "\n",
    "# rfcmerged_model = rfcmergedd.fit(x_train_mergedd, y_train_merged)\n",
    "\n",
    "# rfcmergepred = rfcmerged_model.predict(x_test_merged)\n",
    "\n",
    "# print('Accuracy score :- {}'.format(round(accuracy_score(y_test_merged, rfcmergepred), 2)))\n",
    "# print(\"Train data accuracy:\",accuracy_score(y_train_merged,rfcmergepred)) \n",
    "\n",
    "# print(format(classification_report(y_test_merged, rfcmergepred,zero_division=1)))\n",
    "rfcmerged_model = RandomForestClassifier().fit(x_train_mergedd, y_train_merged)\n",
    "mymodel = open('rtctrainmod.sav', 'wb')\n",
    "pickle.dump( rfcmerged_model, mymodel)\n",
    "mymodel.close()\n",
    "rfcpredav = rfcmerged_model.predict(x_test_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1940e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'rtctrainmod.sav'\n",
    "saved_clf = pickle.load(open(filename, 'rb'))\n",
    "saved_clf.score(x_test_merged, y_test_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6ea914",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---Test Set Results---\")\n",
    "print(\"Accuracy with logreg: {}\".format(accuracy_score(y_test_merged, rfcpredav)))\n",
    "print(classification_report(y_test_merged, rfcpredav))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d652b9",
   "metadata": {},
   "source": [
    "Using the saved random forest classifier model of merged dataset on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef565ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'rtctrainmod.sav'\n",
    "saved_clfa = pickle.load(open(filename, 'rb'))\n",
    "saved_clfa.score(x_testtest, y_testtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266fe20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictionmodela = rfcmerged_model.predict(x_testtest)\n",
    "print(\"---Test Set Results---\")\n",
    "print(\"Accuracy with logreg: {}\".format(accuracy_score(y_testtest, y_predictionmodela)))\n",
    "print(classification_report(y_testtest, y_predictionmodela))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3fd039",
   "metadata": {},
   "source": [
    "Accuracy of the test model after retrained using merged dataset is 0.73"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae16f19",
   "metadata": {},
   "source": [
    "## 7)Deep Learning from the scratch-- Taking the copy of whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d303ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code reference: github.com \n",
    "\n",
    "copya = pd.DataFrame(mydata)\n",
    "\n",
    "#Make a copy:\n",
    "\n",
    "hypertuning = copya.copy()\n",
    "\n",
    "print(hypertuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de4991e",
   "metadata": {},
   "source": [
    "Reducing the length of rows to 1000 to hypertune and regualrize the small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28903822",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypertuning=hypertuning[0:1000]\n",
    "len(hypertuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0371ee9",
   "metadata": {},
   "source": [
    "Merging the headline and short description into sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae29d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypertuning[\"sentence\"]=hypertuning['headline']+hypertuning['short_description']\n",
    "hypertuning[\"category\"]=hypertuning['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223239e5",
   "metadata": {},
   "source": [
    "removing all other columns rather than sentence and category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe48828",
   "metadata": {},
   "outputs": [],
   "source": [
    "del hypertuning['authors']\n",
    "del hypertuning['link']\n",
    "del hypertuning['headline']\n",
    "del hypertuning['date']\n",
    "del hypertuning['id']\n",
    "del hypertuning['short_description']\n",
    "del hypertuning['c_id']\n",
    "\n",
    "hypertuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fac8466",
   "metadata": {},
   "source": [
    "building vocabulary from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0fd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 100\n",
    "\n",
    " \n",
    "def build_vocabulary(sentence_list):\n",
    "    unique_words = \" \".join(sentence_list).strip().split()\n",
    "    word_count = Counter(unique_words).most_common()\n",
    "    vocabulary = {}\n",
    "    for word, _ in word_count:\n",
    "        vocabulary[word] = len(vocabulary)        \n",
    "\n",
    "    return vocabulary\n",
    "\n",
    "vocabulary = build_vocabulary(hypertuning[\"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb31a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(500, ))\n",
    "embedding_layer = Embedding(len(vocabulary),\n",
    "                            16,input_length=500)(inputs)\n",
    "word_embedding= BatchNormalization()(embedding_layer)\n",
    "\n",
    "x = LSTM(128)(word_embedding)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=[inputs], outputs=predictions)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc811b6",
   "metadata": {},
   "source": [
    "Create datasets (Only take up to time_steps words for memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e611fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = hypertuning['sentence'].tolist()\n",
    "train_text = [' '.join(t.split()[0:time_steps]) for t in train_text]\n",
    "train_text = np.array(train_text)\n",
    "train_label = np.array(hypertuning['category'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a04d5f",
   "metadata": {},
   "source": [
    "Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74c98a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 500\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_text)\n",
    "post_seq = tokenizer.texts_to_sequences(train_text)\n",
    "post_seq_padded = pad_sequences(post_seq, maxlen=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e727c8",
   "metadata": {},
   "source": [
    "Splitting the dataset to hypertune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0720c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainhypertuning, X_testhypertuning, y_trainhypertuning, y_testhypertuning = train_test_split(post_seq_padded, train_label, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab15abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([X_trainhypertuning], y=to_categorical(y_trainhypertuning), verbose=1, validation_split=0.25, \n",
    "          shuffle=False, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c81780",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_testhypertuning,to_categorical(y_testhypertuning))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f51134",
   "metadata": {},
   "source": [
    "### - To decrease overfitting in my simple model and for that aim I decreased my sample to 1000.\n",
    "### - At the above we can see my base model there is huge overfitting like almost %30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7677144",
   "metadata": {},
   "source": [
    "## Adding Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb943af",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "y = {}\n",
    "loss = []\n",
    "acc = []\n",
    "dropouts = [0.0, 0.1, 0.2, 0.3]\n",
    "for dropout in dropouts:\n",
    "    print (\"Dropout: \", dropout)\n",
    "\n",
    "    inputs = Input(shape=(500, ))\n",
    "    embedding_layer = Embedding(len(vocabulary),\n",
    "                            16,input_length=500)(inputs)\n",
    "    word_embedding= BatchNormalization()(embedding_layer)\n",
    "\n",
    "    x = LSTM(128)(word_embedding)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "    model = Model(inputs=[inputs], outputs=predictions)\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "    model_simple = model.fit([X_trainhypertuning], batch_size=64, y=to_categorical(y_trainhypertuning), verbose=1, validation_split=0.25, \n",
    "          shuffle=False, epochs=5)\n",
    "    score = model.evaluate(X_testhypertuning, to_categorical(y_testhypertuning),verbose=0)\n",
    "    y[dropout] = model.predict(X_testhypertuning)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    result[dropout] = copy.deepcopy(model_simple.history)   \n",
    "    loss.append(score[0])\n",
    "    acc.append(score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876bbee2",
   "metadata": {},
   "source": [
    "### As we can see dropout with rate 0.1 helped us do decrease overfitting to %25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b3de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.1\n",
    "\n",
    "plt.bar(dropouts, acc, width, align='center')\n",
    "#plt.figure(figsize=(50,50))\n",
    "plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "plt.tick_params(axis='both', which='minor', labelsize=10)\n",
    "\n",
    "plt.ylabel('Accuracy',size = 20)\n",
    "plt.xlabel('Dropout', size = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff2fbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.1\n",
    "\n",
    "plt.bar(dropouts, loss, width, align='center',color = 'green')\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "plt.tick_params(axis='both', which='minor', labelsize=10)\n",
    "\n",
    "plt.ylabel('Loss',size = 20)\n",
    "plt.xlabel('Dropout', size = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46708861",
   "metadata": {},
   "source": [
    "fine tuning hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ac9169",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "y = {}\n",
    "loss = []\n",
    "acc = []\n",
    "\n",
    "learning_rates = [0.1,0.01,0.001]\n",
    "lr_weight_decay = 0.95  \n",
    "\n",
    "for lr in learning_rates:\n",
    "    print (\"Learning rate: \", lr)\n",
    "    \n",
    "    inputs = Input(shape=(500, ))\n",
    "    embedding_layer = Embedding(len(vocabulary),\n",
    "                            16,input_length=500)(inputs)\n",
    "    word_embedding= BatchNormalization()(embedding_layer)\n",
    "\n",
    "    x = LSTM(128)(word_embedding)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "    model = Model(inputs=[inputs], outputs=predictions)\n",
    "    adam = optimizers.Adam(lr,decay=lr_weight_decay)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    model_simple = model.fit([X_trainhypertuning], batch_size=64, y=to_categorical(y_trainhypertuning), verbose=1, validation_split=0.25, \n",
    "          shuffle=False, epochs=5)\n",
    "    score = model.evaluate(X_testhypertuning, to_categorical(y_testhypertuning),verbose=0)\n",
    "    y[lr] = model.predict(X_testhypertuning)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    result[lr] = copy.deepcopy(model_simple.history)   \n",
    "    loss.append(score[0])\n",
    "    acc.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7e48f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "width = 0.1\n",
    "\n",
    "plt.bar(learning_rates, acc, width, align='center')\n",
    "#plt.figure(figsize=(50,50))\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.tick_params(axis='both', which='minor', labelsize=20)\n",
    "\n",
    "plt.ylabel('Accuracy',size = 20)\n",
    "plt.xlabel('Learning Rate', size = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c787c594",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.1\n",
    "\n",
    "plt.bar(learning_rates, loss, width, align='center',color = 'green')\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "plt.tick_params(axis='both', which='minor', labelsize=10)\n",
    "\n",
    "plt.ylabel('Loss',size = 20)\n",
    "plt.xlabel('Learning rates', size = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf20cda8",
   "metadata": {},
   "source": [
    "## So also we can try different optimizer as RMSPROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea5fd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(500, ))\n",
    "embedding_layer = Embedding(len(vocabulary),\n",
    "                            16,input_length=500)(inputs)\n",
    "word_embedding= BatchNormalization()(embedding_layer)\n",
    "\n",
    "x = LSTM(128)(word_embedding)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=[inputs], outputs=predictions)\n",
    "rmsprop = optimizers.RMSprop(learning_rate=0.001, decay=0.95)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa44b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_simple = model.fit([X_trainhypertuning], batch_size=64, y=to_categorical(y_trainhypertuning), verbose=1, validation_split=0.25, \n",
    "          shuffle=False, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5373e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicted=model.predict(X_testhypertuning)\n",
    "predicted = np.argmax(predicted, axis=1)\n",
    "print(accuracy_score(y_testhypertuning, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0b839c",
   "metadata": {},
   "source": [
    "As we can see from above results we succeded to decrease overfitting to %25 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be827d9c",
   "metadata": {},
   "source": [
    "## As a result of these experiments I can say that Dropout , changing optimizer to rmsprop helped us to acvhieve better performance so now we can try these changes on our whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2227aae",
   "metadata": {},
   "source": [
    "Taking a copy of the whole dataframe to optimize using rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7583c87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "copya = pd.DataFrame(mydata)\n",
    "\n",
    "#Make a copy:\n",
    "\n",
    "hypertuninga = copya.copy()\n",
    "\n",
    "print(hypertuninga)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35a0261",
   "metadata": {},
   "source": [
    "Merging the headline and short descsription to a sentence column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f91ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypertuninga[\"sentence\"]=hypertuninga['headline']+hypertuninga['short_description']\n",
    "hypertuninga[\"category\"]=hypertuninga['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92a0252",
   "metadata": {},
   "source": [
    "Removing all the columns rather than category and sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f570a2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del hypertuninga['authors']\n",
    "del hypertuninga['link']\n",
    "del hypertuninga['headline']\n",
    "del hypertuninga['date']\n",
    "del hypertuninga['id']\n",
    "del hypertuninga['short_description']\n",
    "del hypertuninga['c_id']\n",
    "\n",
    "hypertuninga\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a1a23a",
   "metadata": {},
   "source": [
    "Building a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ff9185",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = build_vocabulary(hypertuninga[\"sentence\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f20d30",
   "metadata": {},
   "source": [
    "Create datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb6615",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = hypertuninga['sentence'].tolist()\n",
    "train_text = [' '.join(t.split()[0:time_steps]) for t in train_text]\n",
    "train_text = np.array(train_text)\n",
    "train_label = np.array(hypertuninga['category'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5959a4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 500\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_text)\n",
    "post_seq = tokenizer.texts_to_sequences(train_text)\n",
    "post_seq_padded = pad_sequences(post_seq, maxlen=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5121134",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainhyper, X_testhyper, y_trainhyper, y_testhyper = train_test_split(post_seq_padded, train_label, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c084bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = Input(shape=(500, ))\n",
    "embedding_layer = Embedding(len(vocabulary),\n",
    "                            16,input_length=500)(inputs)\n",
    "word_embedding= BatchNormalization()(embedding_layer)\n",
    "\n",
    "x = LSTM(128)(word_embedding)\n",
    "x = Dense(64, activation='relu',kernel_regularizer=regularizers.l2(0.05))(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(32, activation='relu',kernel_regularizer=regularizers.l2(0.05))(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=[inputs], outputs=predictions)\n",
    "rmsprop = optimizers.RMSprop(learning_rate=0.001, decay=0.95)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ced2f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([X_trainhyper], batch_size=128, y=to_categorical(y_trainhyper), verbose=1, validation_split=0.25, \n",
    "          shuffle=False, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d819a1",
   "metadata": {},
   "source": [
    "# summarize history for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb35d4c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c8e5ba",
   "metadata": {},
   "source": [
    "# summarize history for loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe82782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
